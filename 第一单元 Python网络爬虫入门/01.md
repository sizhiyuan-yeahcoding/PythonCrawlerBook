By  [一页编程](http://www.jianshu.com/users/c3ea87d65161/)
***
今天我们来学习开发第一个Python网络爬虫。
获得一个网页最简单的一行代码就是：
```python
r=requests.get(url)
```
这里边，我们通过给定get方法和url来构造一个像服务器请求资源的Request对象。这个对象是属于requests库内部生成的。而requests.get()返的内容是一个Response对象。Response对象包含从服务器返回的所有的相关资源。

###GET方法
requests.get()的完整的使用方法如下：
```python
r=requests.get(url, params=None, **kwargs)
```
* url是获得页面的url链接；
* params指的是在url中增加的额外参数，它可以是字典，也可以是字节流格式，它是可选的；
* 还有12个控制访问的参数也是可选的。

如果我们打开requests.get()方法源代码，我们可以看到，get()方法。实际上，它使用了request()方法来封装。
```python
def get(url, params=None, **kwargs):
    """Sends a GET request.

    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary or bytes to be sent in the query string for the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    """

    kwargs.setdefault('allow_redirects', True)
    return request('get', url, params=params, **kwargs)
```
实际上，requests库一共提供了7个常用方法，除了第一个request方法是基础方法外，其他的6个方法都是通过调用request方法来实现的。大家可以这样认为，requests库其实只有一个方法就是request()方法。
但是为了让大家编写程序更方便，所以它提供了额外6个方法。

###Response对象
在我们的第一个网络爬虫代码中，最重要的两个对象就是Request跟Response两个对象，而这两个对象中与获得网络内容相关的Response对象又是重中之重，它包含了爬虫返回的全部内容。
下面我来实际演示一下，并重点看一下response对象。
```python
>>> import requests
>>> r = requests.get('http://www.baidu.com')
>>> print(r.status_code)
200
>>> type(r)
<class 'requests.models.Response'>
>>> r.headers
{'Server': 'bfe/1.0.8.18', 'Date': 'Sat, 01 Apr 2017 00:51:24 GMT', 'Content-Type': 'text/html', 'Last-Modified': 'Mon, 23 Jan 2017 13:27:27 GMT', 'Transfer-Encoding': 'chunked', 'Connection': 'Keep-Alive', 'Cache-Control': 'private, no-cache, no-store, proxy-revalidate, no-transform', 'Pragma': 'no-cache', 'Set-Cookie': 'BDORZ=27315; max-age=86400; domain=.baidu.com; path=/', 'Content-Encoding': 'gzip'}
>>> r.url
'http://www.baidu.com/'
```
1、首先我们导入requests库，用get方法去访问百度的主页。
2、我们用r.status_code来检测这个请求的状态码，如果状态码是200，说明访问成功，如果状态码不是200，那就是访问失败。
3、我们用type(r)检测r的类型，我们看到这个时候返回的，表示它是一个类，这个类的名是Response。
4、我们还可以用r.headers，返回get请求获得页面的头部信息。
5、我们用r.url获取请求信息的url，事实上Response对象也包含了我们去向服务器请求的Request信息。

###Response属性

在Response对象中，最常用的有如下5个属性：

属性 | 说明
------------- | -------------
r.status_code  | HTTP请求的返回状态，200表示成功
r.text | 从URL获得的网络页面的字符串形式
r.encoding | 从HTTP的header的中获取或猜测的编码方式
r.apparent_encoding | 从相应的内容\文本中分析出来的表达方式
r.content | HTTP响应内容的二进制形式

在使用get方法获取网上资源的时候，有这么一个基本的流程：首先呢，我们用r.status_code来检查返回的response对象它的状态，如果他是200，那我就可以用r.text、r.encoding、r.apparent_encoding、r.content等去解析返回的内容；如果返回状态码是404或者其他，那就说明我们这次url的访问，因为某种原因出错，或产生异常了。
###字符编码
我们继续看爬去百度首页的例子：
```python
>>> r = requests.get('http://www.baidu.com')
>>> r.text
'<!DOCTYPE html>\r\n<!--STATUS OK--><html> <head><meta http-equiv=content-type content=text/html;charset=utf-8><meta http-equiv=X-UA-Compatible content=IE=Edge><meta content=always name=referrer><link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css><title>ç\x99¾åº¦ä¸\x80ä¸\x8bï¼\x8cä½\xa0å°±ç\x9f¥é\x81\x93</title></head> <body link=#0000cc> <div id=wrapper> <div id=head> <div class=head_wrapper> <div class=s_form> <div class=s_form_wrapper> <div id=lg> <img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129> </div> <form id=form name=f action=//www.baidu.com/s class=fm> <input type=hidden name=bdorz_come value=1> <input type=hidden name=ie value=utf-8> <input type=hidden name=f value=8> <input type=hidden name=rsv_bp value=1> <input type=hidden name=rsv_idx value=1> <input type=hidden name=tn value=baidu><span class="bg s_ipt_wr"><input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus></span><span class="bg s_btn_wr"><input type=submit id=su value=ç\x99¾åº¦ä¸\x80ä¸\x8b class="bg s_btn"></span> </form> </div> </div> <div id=u1> <a href=http://news.baidu.com name=tj_trnews class=mnav>æ\x96°é\x97»</a> <a href=http://www.hao123.com name=tj_trhao123 class=mnav>hao123</a> <a href=http://map.baidu.com name=tj_trmap class=mnav>å\x9c°å\x9b¾</a> <a href=http://v.baidu.com name=tj_trvideo class=mnav>è§\x86é¢\x91</a> <a href=http://tieba.baidu.com name=tj_trtieba class=mnav>è´´å\x90§</a> <noscript> <a href=http://www.baidu.com/bdorz/login.gif?login&tpl=mn&u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb>ç\x99»å½\x95</a> </noscript> <script>document.write(\'<a href="http://www.baidu.com/bdorz/login.gif?login&tpl=mn&u=\'+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&")+ "bdorz_come=1")+ \'" name="tj_login" class="lb">ç\x99»å½\x95</a>\');</script> <a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;">æ\x9b´å¤\x9aäº§å\x93\x81</a> </div> </div> </div> <div id=ftCon> <div id=ftConw> <p id=lh> <a href=http://home.baidu.com>å\x85³äº\x8eç\x99¾åº¦</a> <a href=http://ir.baidu.com>About Baidu</a> </p> <p id=cp>©2017 Baidu <a href=http://www.baidu.com/duty/>ä½¿ç\x94¨ç\x99¾åº¦å\x89\x8då¿\x85è¯»</a>  <a href=http://jianyi.baidu.com/ class=cp-feedback>æ\x84\x8fè§\x81å\x8f\x8dé¦\x88</a> äº¬ICPè¯\x81030173å\x8f·  <img src=//www.baidu.com/img/gs.gif> </p> </div> </div> </div> </body> </html>\r\n'
>>> 
```
这里边我发现它的内容中很多都是乱码，我们看不清他的内容是什么，我们这时候可以看它的编码是什么：
```python
>>> r.encoding
'ISO-8859-1'
>>> 
```
噢，他既然是这样一个编码，我们再看一下另外一个编码，apparent_encoding是什么：
```python
>>> r.apparent_encoding
'utf-8'
>>> 
```
我们发现apparent_encoding是utf-8编码，如果我用这样的编码，来替换r.encoding，然后我再用r.text输出：
```python
>>> r.encoding = 'utf-8'
>>> r.text
'<!DOCTYPE html>\r\n<!--STATUS OK--><html> <head><meta http-equiv=content-type content=text/html;charset=utf-8><meta http-equiv=X-UA-Compatible content=IE=Edge><meta content=always name=referrer><link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css><title>百度一下，你就知道</title></head> <body link=#0000cc> <div id=wrapper> <div id=head> <div class=head_wrapper> <div class=s_form> <div class=s_form_wrapper> <div id=lg> <img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129> </div> <form id=form name=f action=//www.baidu.com/s class=fm> <input type=hidden name=bdorz_come value=1> <input type=hidden name=ie value=utf-8> <input type=hidden name=f value=8> <input type=hidden name=rsv_bp value=1> <input type=hidden name=rsv_idx value=1> <input type=hidden name=tn value=baidu><span class="bg s_ipt_wr"><input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus></span><span class="bg s_btn_wr"><input type=submit id=su value=百度一下 class="bg s_btn"></span> </form> </div> </div> <div id=u1> <a href=http://news.baidu.com name=tj_trnews class=mnav>新闻</a> <a href=http://www.hao123.com name=tj_trhao123 class=mnav>hao123</a> <a href=http://map.baidu.com name=tj_trmap class=mnav>地图</a> <a href=http://v.baidu.com name=tj_trvideo class=mnav>视频</a> <a href=http://tieba.baidu.com name=tj_trtieba class=mnav>贴吧</a> <noscript> <a href=http://www.baidu.com/bdorz/login.gif?login&tpl=mn&u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb>登录</a> </noscript> <script>document.write(\'<a href="http://www.baidu.com/bdorz/login.gif?login&tpl=mn&u=\'+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&")+ "bdorz_come=1")+ \'" name="tj_login" class="lb">登录</a>\');</script> <a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;">更多产品</a> </div> </div> </div> <div id=ftCon> <div id=ftConw> <p id=lh> <a href=http://home.baidu.com>关于百度</a> <a href=http://ir.baidu.com>About Baidu</a> </p> <p id=cp>©2017 Baidu <a href=http://www.baidu.com/duty/>使用百度前必读</a>  <a href=http://jianyi.baidu.com/ class=cp-feedback>意见反馈</a> 京ICP证030173号  <img src=//www.baidu.com/img/gs.gif> </p> </div> </div> </div> </body> </html>\r\n'
>>> 
```
噢，看到了很多的中文的字符，包括百度的相关信息。这说明什么呢？
所以为了更好的理解刚才我们的展示，我们需要清楚地理解两种编码的区别。
简单说，网络上的资源，它有它的编码，如果没有编码我们将看不懂，我们将没办法用有效的解析方式，使得人类可读这样的内容，所以我们需要编码这样一个概念。
#####r.encoding
>r.encoding编码方式是从http header中的charset字段获得的。如果http的header中有这样一个字段，说明我们访问的服务器对他资源的编码是有要求的，而这样的编码会获得回来，存在r.encoding中。但是并不是所有的服务器，对他的资源编码都是有相关要求，所以如果header中不存在charset字段，我们将默认编码设为’ISO-8859-1‘，这也是我们看到当我们访问baidu的时候，我们默认的是这样的一个编码，但是这样的编码并不能解析中文。

#####r.apparent_encoding
>apparent_encoding是根据http的内容部分，而不是头部分去分析内容中出现文本可能的编码形式。原则来说，apparent_encoding的编码比encoding更加准确。因为encoding其实并没有分析内容，他只是从header的相关字段中提取编码方式，而apparent_encoding确实是在实实在在的分析内容，并且找到其中可能的编码.

所以当我们用encoding不能正确解码返回的内容时，我们要用apparent_encoding来解除相关的编码信息，这也是为什么我们当把apparent_encoding赋予encoding之后，我们就能够读到r.text中的中文的原因。